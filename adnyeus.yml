# Exousia Build Configuration
# BlueBuild-compatible YAML specification for declarative bootc image builds
# https://blue-build.org/reference/module/

name: exousia
description: DevSecOps-hardened Fedora bootc image with Sway desktop
image-version: 43

# Base image configuration - can be overridden via build args
base-image: quay.io/fedora/fedora-sway-atomic:43
image-type: fedora-bootc  # or fedora-bootc

# Desktop environment selection
# Use either 'window_manager' or 'desktop_environment', not both
desktop:
  window_manager: sway  # Options: sway, hyprland
  # desktop_environment: kde  # Options: kde, mate
  include_common: true  # Include common base packages

# Container metadata
labels:
  org.opencontainers.image.title: "Exousia"
  org.opencontainers.image.description: "Custom Fedora bootc image with Sway desktop and opinionated package selection"
  org.opencontainers.image.source: "https://github.com/borninthedark/exousia"
  org.opencontainers.image.licenses: "MIT"
  maintainer: "uryu"

# Build configuration
build:
  enable_plymouth: true
  enable_rke2: true  # Enable RKE2 Kubernetes for immutable k8s infrastructure

  # Sway Configuration Source Selection
  # See: https://docs.fedoraproject.org/en-US/fedora-sericea/configuration-guide/
  #
  # false (default): Use custom Exousia configs from custom-configs/sway/
  #   - Copies custom sway.desktop, environment, and start-sway script
  #   - Overrides Fedora Sway SIG configurations
  #
  # true: Keep upstream Fedora Sway configurations
  #   - Preserves sway-config-fedora or sway-config-upstream from base image
  #   - Fedora uses layered config system:
  #     * /usr/share/sway/config.d/*.conf (packaged configs)
  #     * /etc/sway/config.d/*.conf (system overrides)
  #     * ~/.config/sway/config.d/*.conf (user overrides)
  #   - Swap profiles with: dnf swap sway-config sway-config-upstream
  use_upstream_sway_config: false

# Modules define the build steps
modules:
  # System users configuration
  - type: files
    files:
      - src: sysusers/bootc.conf
        dst: /usr/lib/sysusers.d/bootc.conf
        mode: "0644"

  # Initialize system users
  - type: script
    scripts:
      - |
        test -f /etc/passwd || touch /etc/passwd
        test -f /etc/group  || touch /etc/group
        systemd-sysusers || true
        systemd-sysusers --root=/ /usr/lib/sysusers.d/bootc.conf

  # Container authentication
  - type: files
    files:
      - src: containers-auth.conf
        dst: /usr/lib/tmpfiles.d/containers-auth.conf
        mode: "0644"
      - src: ./bootc-secrets/auth.json
        dst: /usr/lib/container-auth.json
        mode: "0600"

  - type: script
    scripts:
      - ln -sfr /usr/lib/container-auth.json /etc/ostree/auth.json

  # Plymouth theme files (toggleable per image type)
  - type: files
    condition: enable_plymouth == true
    files:
      - src: custom-configs/plymouth/themes/bgrt-better-luks/
        dst: /usr/share/plymouth/themes/bgrt-better-luks/
        mode: "0644"

  # Custom repositories
  - type: files
    files:
      - src: custom-repos/
        dst: /etc/yum.repos.d/
        mode: "0644"

  # Custom configurations
  - type: files
    files:
      - src: custom-configs/
        dst: /etc/
        mode: "0644"

  # Custom scripts
  - type: files
    files:
      - src: custom-scripts/
        dst: /usr/local/bin/
        mode: "0755"

  # Sway session files (custom configs - skipped if use_upstream_sway_config == true)
  - type: files
    condition: use_upstream_sway_config == false
    files:
      - src: custom-configs/sway/sway.desktop
        dst: /usr/share/wayland-sessions/sway.desktop
        mode: "0644"
      - src: custom-configs/sway/environment
        dst: /etc/sway/environment
        mode: "0644"
      - src: custom-configs/sway/start-sway
        dst: /usr/bin/start-sway
        mode: "0755"

  # Package management using new YAML-based loader
  # Automatically loads packages based on desktop.window_manager or desktop.desktop_environment
  - type: package-loader
    window_manager: sway  # Loaded from packages/window-managers/sway.yml
    include_common: true  # Also loads packages/common/base.yml

  # Flatpak setup
  - type: script
    scripts:
      - flatpak remote-add --if-not-exists flathub https://flathub.org/repo/flathub.flatpakrepo

  # ============================================================================
  # RKE2 Kubernetes Integration (optional, enabled via build.enable_rke2)
  # Follows official quickstart: https://docs.rke2.io/install/quickstart
  # ============================================================================

  # RKE2 management CLI (Python)
  - type: files
    condition: enable_rke2 == true
    files:
      - src: tools/rke2_ops.py
        dst: /usr/local/bin/rke2_ops
        mode: "0755"

  # RKE2 Server installation - Step 1: Run the installer
  # This installs rke2-server service and rke2 binary
  - type: script
    condition: enable_rke2 == true
    scripts:
      - |
        # Install RKE2 server using official install script
        # Default INSTALL_RKE2_TYPE is "server" so we don't need to specify it
        INSTALL_RKE2_BIN_DIR=/var/lib/rancher/rke2/bin \
          curl -sfL https://get.rke2.io | sh -

        # Ensure the RKE2 binary is in the expected location for tests
        if [ -x /var/lib/rancher/rke2/bin/rke2 ] && [ ! -e /usr/local/bin/rke2 ]; then
          ln -s /var/lib/rancher/rke2/bin/rke2 /usr/local/bin/rke2
        elif [ -x /usr/bin/rke2 ] && [ ! -e /usr/local/bin/rke2 ]; then
          ln -s /usr/bin/rke2 /usr/local/bin/rke2
        fi

        if [ ! -x /usr/local/bin/rke2 ]; then
          echo "✗ RKE2 binary missing after install" >&2
          exit 1
        fi

        # Ensure kubectl from the RKE2 bundle is present
        if [ -x /var/lib/rancher/rke2/bin/kubectl ] && [ ! -e /usr/local/bin/kubectl ]; then
          ln -s /var/lib/rancher/rke2/bin/kubectl /usr/local/bin/kubectl
        fi

        if [ ! -x /var/lib/rancher/rke2/bin/kubectl ]; then
          echo "✗ RKE2 kubectl not found after install" >&2
          exit 1
        fi

        # Verify installation
        # Note: RKE2 binary location may vary (RPM installs to /usr/bin, script installs to /usr/local/bin)
        if [ -f /usr/local/bin/rke2 ] || [ -f /usr/bin/rke2 ]; then
            echo "✓ RKE2 binary installed"
        else
            echo "✗ RKE2 binary not found"
        fi
        test -f /usr/lib/systemd/system/rke2-server.service && echo "✓ rke2-server.service installed" || echo "✗ rke2-server.service not found"

  # RKE2 configuration directory
  - type: script
    condition: enable_rke2 == true
    scripts:
      - |
        # Create RKE2 config directory
        mkdir -p /etc/rancher/rke2

  # RKE2 configuration files (already copied via custom-configs)
  # Ensure these files exist in your custom-configs directory:
  # - custom-configs/rancher/rke2/registries.yaml -> /etc/rancher/rke2/registries.yaml
  # - custom-configs/rancher/rke2/config.yaml -> /etc/rancher/rke2/config.yaml
  # The config.yaml should contain server-specific settings like:
  #   write-kubeconfig-mode: "0644"
  #   tls-san:
  #     - "your-server-hostname"
  #   node-label:
  #     - "node-role.kubernetes.io/control-plane=true"

  # RKE2 systemd drop-in directory for custom overrides
  - type: script
    condition: enable_rke2 == true
    scripts:
      - mkdir -p /etc/systemd/system/rke2-server.service.d

  # RKE2 firewall configuration - open required ports
  - type: script
    condition: enable_rke2 == true
    scripts:
      - |
        # Open required RKE2 server ports
        firewall-offline-cmd --add-port=6443/tcp      # Kubernetes API server
        firewall-offline-cmd --add-port=9345/tcp      # RKE2 supervisor API (for agent registration)
        firewall-offline-cmd --add-port=10250/tcp     # Kubelet metrics
        firewall-offline-cmd --add-port=2379-2380/tcp # etcd client/peer communication

  # RKE2 data directories and paths
  - type: script
    condition: enable_rke2 == true
    scripts:
      - |
        # Create required directories
        mkdir -p /var/lib/rancher/rke2
        mkdir -p /var/lib/rancher/rke2/bin
        mkdir -p /var/lib/rancher/rke2/server

        # Symlink kubectl and other tools to a standard location
        # These will be available after first boot when RKE2 runs
        mkdir -p /usr/local/bin

  # RKE2 SELinux contexts
  - type: script
    condition: enable_rke2 == true
    scripts:
      - |
        # Set proper SELinux contexts for RKE2 directories
        semanage fcontext -a -t container_var_lib_t "/var/lib/rancher/rke2(/.*)?" || true
        restorecon -R /var/lib/rancher/rke2 || true

  # RKE2 kernel arguments for proper cgroups v2 support
  - type: script
    condition: enable_rke2 == true
    scripts:
      - |
        mkdir -p /usr/lib/bootc/kargs.d
        echo 'kargs = ["systemd.unified_cgroup_hierarchy=1", "swapaccount=1"]' > /usr/lib/bootc/kargs.d/99-rke2.toml

  # RKE2 MOTD with helpful commands
  - type: files
    condition: enable_rke2 == true
    files:
      - src: custom-configs/rke2/motd
        dst: /etc/motd
        mode: "0644"

  # Plymouth configuration (all images when enabled)
  - type: script
    condition: enable_plymouth == true
    scripts:
      - |
        rm -rf /var/tmp && ln -sf /tmp /var/tmp
        mkdir -p /usr/lib/dracut/dracut.conf.d
        echo 'add_dracutmodules+=" plymouth ostree "' > /usr/lib/dracut/dracut.conf.d/plymouth.conf
        plymouth-set-default-theme bgrt-better-luks
        kver=$(basename /usr/lib/modules/*)
        dracut -vf /usr/lib/modules/$kver/initramfs.img $kver

  # System services (common to all image types)
  - type: systemd
    system:
      enabled:
        - libvirtd.service
        - systemd-resolved.service
        - NetworkManager.service
        - greetd.service
    default-target: graphical.target

  # RKE2 Server service - Step 2: Enable rke2-server.service
  # The service will start on first boot and subsequent reboots
  - type: systemd
    condition: enable_rke2 == true
    system:
      enabled:
        - rke2-server.service

  # Ensure /var layout matches bootc lint expectations
  - type: script
    scripts:
      - |
        set -euxo pipefail

        # /var/run should be a symlink to /run for bootc lint
        if [ ! -L /var/run ]; then
          rm -rf /var/run
          ln -s ../run /var/run
        fi

        # Drop build-time cache/log artifacts so tmpfiles can own /var
        rm -f /var/log/dnf5.log /var/log/dnf5.log.[0-9]* || true
        rm -rf /var/cache/dnf /var/cache/libdnf5 /var/cache/etckeeper || true
        rm -rf /var/lib/dnf || true

  # Validation and finalization
  - type: script
    scripts:
      - bootc container lint
      - restorecon -vv /usr/local/bin/tuigreet || true
      - restorecon -vv /usr/local/bin/rke2_ops || true
      - restorecon -vv /usr/local/bin/rke2-kubectl || true
      - |
        # Check RKE2 installation (binary may be in /usr/bin or /usr/local/bin)
        if [ -f /usr/local/bin/rke2 ] || [ -f /usr/bin/rke2 ]; then
            echo "✓ RKE2 installed"
        else
            echo "○ RKE2 not installed"
        fi
      - test -f /usr/lib/systemd/system/rke2-server.service && echo "✓ rke2-server.service configured" || echo "○ rke2-server.service not found"
      - |
        if [ "${enable_rke2:-false}" = "true" ]; then
          rpm -q \
            curl \
            iptables \
            container-selinux \
            policycoreutils-python-utils \
            cryptsetup \
            python3
        fi
      - echo "composefs=true" >> /etc/ostree/repo.config || true

  # Post-installation notes
  - type: script
    condition: enable_rke2 == true
    scripts:
      - echo "RKE2 Server installation configured. On first boot, rke2-server service will start automatically."
